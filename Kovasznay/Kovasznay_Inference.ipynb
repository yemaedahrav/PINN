{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfUgr12TxZwj",
        "outputId": "9886031d-b981-439e-88d7-0c8968f5868f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyDOE\n",
            "  Downloading pyDOE-0.3.8.zip (22 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pyDOE) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from pyDOE) (1.7.3)\n",
            "Building wheels for collected packages: pyDOE\n",
            "  Building wheel for pyDOE (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyDOE: filename=pyDOE-0.3.8-py3-none-any.whl size=18184 sha256=b5e31ee2cb7bc3b361d3c0e2988ebb668a310f073803cf3105b081381ef4d0d0\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/3e/fa/5705bf59c2053c17c4799c3ab66a2e356c32f40a3044fe2134\n",
            "Successfully built pyDOE\n",
            "Installing collected packages: pyDOE\n",
            "Successfully installed pyDOE-0.3.8\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import matplotlib.gridspec as gridspec\n",
        "import scipy.io\n",
        "from scipy.interpolate import griddata\n",
        "\n",
        "!pip install pyDOE\n",
        "from pyDOE import lhs\n",
        "\n",
        "from collections import OrderedDict\n",
        "from tqdm import tqdm\n",
        "\n",
        "sns.set_style(\"white\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kiB7n-jxxrBq"
      },
      "outputs": [],
      "source": [
        "# Multi-layer Perceptron (Deep Neural Network)\n",
        "class DNN(torch.nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super(DNN, self).__init__()\n",
        "        \n",
        "        self.depth = len(layers) - 1\n",
        "        self.activation = torch.nn.Tanh\n",
        "        \n",
        "        layer_list = list()\n",
        "        for i in range(self.depth - 1): \n",
        "            layer_list.append(('layer_%d' % i, torch.nn.Linear(layers[i], layers[i+1])))\n",
        "            layer_list.append(('activation_%d' % i, self.activation()))\n",
        "            \n",
        "        layer_list.append(('layer_%d' % (self.depth - 1), torch.nn.Linear(layers[-2], layers[-1])))\n",
        "        layerDict = OrderedDict(layer_list)\n",
        "        \n",
        "        self.layers = torch.nn.Sequential(layerDict)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layers(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kURWSzsx5MQ"
      },
      "outputs": [],
      "source": [
        "# Physics Informed Neural Network\n",
        "class PINN():\n",
        "    def __init__(self, X_s, s, X_f, layers, lb, ub, nu):\n",
        "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "        # boundary conditions\n",
        "        self.lb = torch.tensor(lb).float().to(device)\n",
        "        self.ub = torch.tensor(ub).float().to(device)\n",
        "        \n",
        "        # data\n",
        "        self.x_s = torch.tensor(X_s[:, 0:1], requires_grad=True).float().to(device)\n",
        "        self.y_s = torch.tensor(X_s[:, 1:2], requires_grad=True).float().to(device)\n",
        "        self.x_f = torch.tensor(X_f[:, 0:1], requires_grad=True).float().to(device)\n",
        "        self.y_f = torch.tensor(X_f[:, 1:2], requires_grad=True).float().to(device)\n",
        "        self.s = torch.tensor(s).float().to(device)\n",
        "        \n",
        "        # deep neural networks\n",
        "        self.layers = layers\n",
        "        self.nu = nu\n",
        "        self.dnn = DNN(layers).to(device)\n",
        "        \n",
        "        # optimizers: using the same settings\n",
        "        self.optimizer = torch.optim.LBFGS(\n",
        "            self.dnn.parameters(), \n",
        "            lr=1.0, \n",
        "            max_iter=50000, \n",
        "            max_eval=50000, \n",
        "            history_size=50,\n",
        "            tolerance_grad=1e-5, \n",
        "            tolerance_change=1.0 * np.finfo(float).eps,\n",
        "            line_search_fn=\"strong_wolfe\"      \n",
        "        )\n",
        "        self.iter = 0\n",
        "\n",
        "    def net_s(self, x, y):  \n",
        "        s = self.dnn(torch.cat([x, y], dim=1))\n",
        "        return s\n",
        "    \n",
        "    def net_f(self, x, y):\n",
        "        s = self.net_s(x, y)\n",
        "        u = s[:,0]\n",
        "        v = s[:,1]\n",
        "        p = s[:,2]\n",
        "\n",
        "        du_dx = torch.autograd.grad(inputs=x, outputs=u, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
        "        dv_dx = torch.autograd.grad(inputs=x, outputs=v, grad_outputs=torch.ones_like(v), retain_graph=True, create_graph=True)[0]\n",
        "        dp_dx = torch.autograd.grad(inputs=x, outputs=p, grad_outputs=torch.ones_like(p), retain_graph=True, create_graph=True)[0]\n",
        "        \n",
        "        du_dy = torch.autograd.grad(inputs=y, outputs=u, grad_outputs=torch.ones_like(u), retain_graph=True, create_graph=True)[0]\n",
        "        dv_dy = torch.autograd.grad(inputs=y, outputs=v, grad_outputs=torch.ones_like(v), retain_graph=True, create_graph=True)[0]\n",
        "        dp_dy = torch.autograd.grad(inputs=y, outputs=p, grad_outputs=torch.ones_like(p), retain_graph=True, create_graph=True)[0]\n",
        "\n",
        "        du_dxx = torch.autograd.grad(inputs=x, outputs=du_dx, grad_outputs=torch.ones_like(du_dx), retain_graph=True, create_graph=True)[0]\n",
        "        du_dyy = torch.autograd.grad(inputs=y, outputs=du_dy, grad_outputs=torch.ones_like(du_dy), retain_graph=True, create_graph=True)[0]\n",
        "        dv_dxx = torch.autograd.grad(inputs=x, outputs=dv_dx, grad_outputs=torch.ones_like(dv_dx), retain_graph=True, create_graph=True)[0]\n",
        "        dv_dyy = torch.autograd.grad(inputs=y, outputs=dv_dy, grad_outputs=torch.ones_like(dv_dy), retain_graph=True, create_graph=True)[0]\n",
        "        \n",
        "        f1 = u.squeeze() * du_dx + v.squeeze() * du_dy + dp_dx - self.nu * (du_dxx + du_dyy)\n",
        "        f2 = u.squeeze() * dv_dx + v.squeeze() * dv_dy + dp_dy - self.nu * (dv_dxx + dv_dyy)\n",
        "        f = f1 + f2\n",
        "        return f\n",
        "    \n",
        "    def loss_func(self):\n",
        "        self.optimizer.zero_grad()\n",
        "        \n",
        "        s_pred = self.net_s(self.x_s, self.y_s)\n",
        "        f_pred = self.net_f(self.x_f, self.y_f)\n",
        "#         print(\"s:\", type(self.s))\n",
        "#         print(\"f_pred:\", type(f_pred))\n",
        "#         print(\"s_pred:\", type(s_pred))\n",
        "        loss_s = torch.mean((self.s - s_pred) ** 2)\n",
        "        loss_f = torch.mean(f_pred ** 2)\n",
        "        \n",
        "        loss = loss_s + loss_f\n",
        "        \n",
        "        loss.backward()\n",
        "        self.iter += 1\n",
        "        if self.iter % 100 == 0:\n",
        "            print('Iter %d, Loss: %.5e, Loss_u: %.5e, Loss_f: %.5e' % (self.iter, loss.item(), loss_s.item(), loss_f.item()))\n",
        "        return loss\n",
        "    \n",
        "    def train(self):\n",
        "        self.dnn.train()\n",
        "        self.optimizer.step(self.loss_func)\n",
        "     \n",
        "    def predict(self, X):\n",
        "        device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "        \n",
        "        x = torch.tensor(X[:, 0:1], requires_grad=True).float().to(device)\n",
        "        y = torch.tensor(X[:, 1:2], requires_grad=True).float().to(device)\n",
        "\n",
        "        self.dnn.eval()\n",
        "        s = self.net_s(x, y)\n",
        "        f = self.net_f(x, y)\n",
        "        s = s.detach().cpu().numpy()\n",
        "        f = f.detach().cpu().numpy()\n",
        "        return s, f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtUzPSDH2XWf",
        "outputId": "386dd118-9dc6-4a5e-e115-1ac47b857fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: torch.Size([100])\n",
            "y: torch.Size([100])\n",
            "X: torch.Size([100, 100])\n",
            "Y: torch.Size([100, 100])\n",
            "Exact: torch.Size([100, 100, 3])\n",
            "X_test: (10000, 2)\n",
            "s_test: torch.Size([10000, 3])\n",
            "X_s_train: (200, 2)\n",
            "s_train: torch.Size([200, 3])\n",
            "X_f_train: (10200, 2)\n"
          ]
        }
      ],
      "source": [
        "N_u = 200\n",
        "N_f = 10000\n",
        "\n",
        "Re = 20\n",
        "nu = 1 / Re\n",
        "lamb = 1 / (2 * nu) - np.sqrt(1 / (4 * nu ** 2) + 4 * np.pi ** 2)\n",
        "\n",
        "layers = [2, 50, 50, 50, 50, 3]\n",
        "\n",
        "h = 0.01\n",
        "k = 0.01\n",
        "x = torch.arange(0, 1, h)\n",
        "y = torch.arange(0, 1, k)\n",
        "\n",
        "print(\"x:\", x.shape)\n",
        "print(\"y:\", y.shape)\n",
        "\n",
        "X, Y = np.meshgrid(x,y)\n",
        "X = torch.from_numpy(X)\n",
        "Y = torch.from_numpy(Y)\n",
        "\n",
        "print(\"X:\", X.shape)\n",
        "print(\"Y:\", Y.shape)\n",
        "\n",
        "Exact = torch.zeros(X.shape[0],X.shape[1],3)\n",
        "Exact_U = 1-(torch.exp(lamb*X))*(torch.cos(2*math.pi*Y))\n",
        "Exact_V = (lamb/(2*math.pi))*(torch.exp(lamb*X))*(torch.sin(2*math.pi*Y))\n",
        "Exact_P = (1/2)*(1-(torch.exp(2*lamb*X)))\n",
        "Exact[:,:,0] = Exact_U\n",
        "Exact[:,:,1] = Exact_V\n",
        "Exact[:,:,2] = Exact_P\n",
        "\n",
        "print(\"Exact:\",Exact.shape)\n",
        "\n",
        "X_test = np.hstack((X.flatten()[:,None], Y.flatten()[:,None]))\n",
        "s_test = torch.reshape(Exact, (-1, 3))             \n",
        "\n",
        "print(\"X_test:\", X_test.shape)\n",
        "print(\"s_test:\", s_test.shape)\n",
        "\n",
        "# Domain bounds\n",
        "lb = X_test.min(0)\n",
        "ub = X_test.max(0) \n",
        "\n",
        "\n",
        "idx = np.random.choice(1000, N_u, replace=False)\n",
        "X_s_train = X_test[idx, :]\n",
        "s_train   = s_test[idx, :]\n",
        "\n",
        "print(\"X_s_train:\", X_s_train.shape)\n",
        "print(\"s_train:\", s_train.shape)\n",
        "\n",
        "X_f_train = lb + (ub-lb)*lhs(2, N_f)\n",
        "X_f_train = np.vstack((X_f_train, X_s_train))\n",
        "\n",
        "print(\"X_f_train:\", X_f_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4wu_azTH_WP",
        "outputId": "52243bdc-9107-4a16-ed03-cebe479611ce"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-3-b422b31a158f>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.s = torch.tensor(s).float().to(device)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iter 100, Loss: 3.38184e-03, Loss_u: 2.48239e-03, Loss_f: 8.99448e-04\n",
            "Iter 200, Loss: 2.19783e-03, Loss_u: 1.27746e-03, Loss_f: 9.20368e-04\n",
            "Iter 300, Loss: 1.88676e-03, Loss_u: 9.09894e-04, Loss_f: 9.76867e-04\n"
          ]
        }
      ],
      "source": [
        "model = PINN(X_s_train, s_train, X_f_train, layers, lb, ub, nu)\n",
        "model.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s_pred, f_pred = model.predict(X_test)\n",
        "\n",
        "# Relative L2 Error\n",
        "error_s = np.linalg.norm(s_test-s_pred,2)/np.linalg.norm(s_test,2)\n",
        "print('Relative L2 Error y: %e' % (error_s))\n",
        "\n",
        "# Absolute error\n",
        "u_pred = griddata(X_test, s_pred[:,0].flatten(), (X, Y), method='cubic')\n",
        "v_pred = griddata(X_test, s_pred[:,1].flatten(), (X, Y), method='cubic')\n",
        "p_pred = griddata(X_test, s_pred[:,2].flatten(), (X, Y), method='cubic')\n",
        "\n",
        "Error = np.abs(Exact[:,:,0] - u_pred) + np.abs(Exact[:,:,1] - v_pred) + np.abs(Exact[:,:,2] - p_pred)"
      ],
      "metadata": {
        "id": "54DwYStxL0S0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(7, 7))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "h = ax.imshow(u_pred.T, interpolation='nearest', cmap='rainbow', \n",
        "              extent=[y.min(), y.max(), x.min(), x.max()], \n",
        "              origin='lower', aspect='auto')\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
        "cbar = fig.colorbar(h, cax=cax)\n",
        "cbar.ax.tick_params(labelsize=15) \n",
        "\n",
        "ax.plot(\n",
        "    X_s_train[:,1], \n",
        "    X_s_train[:,0], \n",
        "    'kx', label = 'Data (%d points)' % (s_train[:,0].shape[0]), \n",
        "    markersize = 4,  # marker size doubled\n",
        "    clip_on = False,\n",
        "    alpha=1.0\n",
        ")\n",
        "\n",
        "line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
        "ax.plot(y[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "ax.plot(y[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "ax.plot(y[75]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "\n",
        "ax.set_xlabel('$x$', size=20)\n",
        "ax.set_ylabel('$y$', size=20)\n",
        "ax.legend(\n",
        "    loc='upper center', \n",
        "    bbox_to_anchor=(0.9, -0.05), \n",
        "    ncol=5, \n",
        "    frameon=False, \n",
        "    prop={'size': 15}\n",
        ")\n",
        "ax.set_title('$u(x,y)$', fontsize = 20) # font size doubled\n",
        "ax.tick_params(labelsize=15)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DQC_2-eJVNbH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(7, 7))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "h = ax.imshow(v_pred.T, interpolation='nearest', cmap='rainbow', \n",
        "              extent=[y.min(), y.max(), x.min(), x.max()], \n",
        "              origin='lower', aspect='auto')\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
        "cbar = fig.colorbar(h, cax=cax)\n",
        "cbar.ax.tick_params(labelsize=15) \n",
        "\n",
        "ax.plot(\n",
        "    X_s_train[:,1], \n",
        "    X_s_train[:,0], \n",
        "    'kx', label = 'Data (%d points)' % (s_train[:,0].shape[0]), \n",
        "    markersize = 4,  # marker size doubled\n",
        "    clip_on = False,\n",
        "    alpha=1.0\n",
        ")\n",
        "\n",
        "line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
        "ax.plot(y[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "ax.plot(y[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "ax.plot(y[75]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "\n",
        "ax.set_xlabel('$x$', size=20)\n",
        "ax.set_ylabel('$y$', size=20)\n",
        "ax.legend(\n",
        "    loc='upper center', \n",
        "    bbox_to_anchor=(0.9, -0.05), \n",
        "    ncol=5, \n",
        "    frameon=False, \n",
        "    prop={'size': 15}\n",
        ")\n",
        "ax.set_title('$v(x,y)$', fontsize = 20) # font size doubled\n",
        "ax.tick_params(labelsize=15)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2s8vnxv0mB56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(7, 7))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "h = ax.imshow(p_pred.T, interpolation='nearest', cmap='rainbow', \n",
        "              extent=[y.min(), y.max(), x.min(), x.max()], \n",
        "              origin='lower', aspect='auto')\n",
        "divider = make_axes_locatable(ax)\n",
        "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.10)\n",
        "cbar = fig.colorbar(h, cax=cax)\n",
        "cbar.ax.tick_params(labelsize=15) \n",
        "\n",
        "ax.plot(\n",
        "    X_s_train[:,1], \n",
        "    X_s_train[:,0], \n",
        "    'kx', label = 'Data (%d points)' % (s_train[:,0].shape[0]), \n",
        "    markersize = 4,  # marker size doubled\n",
        "    clip_on = False,\n",
        "    alpha=1.0\n",
        ")\n",
        "\n",
        "line = np.linspace(x.min(), x.max(), 2)[:,None]\n",
        "ax.plot(y[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "ax.plot(y[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "ax.plot(y[75]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
        "\n",
        "ax.set_xlabel('$x$', size=20)\n",
        "ax.set_ylabel('$y$', size=20)\n",
        "ax.legend(\n",
        "    loc='upper center', \n",
        "    bbox_to_anchor=(0.9, -0.05), \n",
        "    ncol=5, \n",
        "    frameon=False, \n",
        "    prop={'size': 15}\n",
        ")\n",
        "ax.set_title('$p(x,y)$', fontsize = 20) # font size doubled\n",
        "ax.tick_params(labelsize=15)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "efyFHTH5mJie"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}